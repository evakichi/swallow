{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2b5074-a644-48f8-8208-9924c2a8efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4376d99-867e-4c74-b323-bacaec8a01f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa69b0dc0b77477fb487aefeb6b077d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d17c37754b14185a89277da87c0cd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e12d12e25844a1a9572b939aebcd61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeee77bd5d04236a13b1d394eee329e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5826601a61e497c9def661912d0ab62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67ac517ea8a45d392414d10cc8de4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d75261baf8a46b58972591f781ed51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a8aa8d094f4678a2b7e7b226b027a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e2cbfa959b4e5c9e19454ccec904d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800d9752cfe0442f8e305b6cc45cf5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a59f05647d74dd5b2cc169fea31efca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3493b66af91b422cba9ad7d69baff2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/131 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47841d51-f2e4-4455-95ae-b9b2fd22091b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "熊本県は、日本の九州地方にあり、多くの観光地が存在します。以下にいくつかを紹介します。\n",
      "\n",
      "1. 熊本城: 熊本市にある城で、世界遺産に登録されています。明治時代に大きな火災に遭い、現在の建物はその後復元されたものです。\n",
      "2. 阿蘇山: 日本で一番大きい火山で、世界遺産に登録されています。阿蘇山は、火山活動が活発で、火口や噴火口が見られます。\n",
      "3. 黒川温泉: 熊本県の阿蘇山の南にある温泉地です。自然豊かな温泉で、温泉旅館が多くあり、観光客が多いです。\n",
      "4. 天草: 熊本県の南にある島で、天草キリシタンが生まれました。天草には、キリシタン関連の歴史的建造物や、美しい海岸が見られます。\n",
      "5. 水前寺公園: 熊本市にある公園で、池や庭園があり、散歩することができます。水前寺公園は、熊本城の近くにあり、熊本城と合わせて訪れることをお勧めします。\n",
      "6. 錦江湾: 熊本県の南にある湾で、美しい海岸と、海水浴や釣りなどのレジャーができます。\n",
      "7. 小国町: 熊本県の北にある町で、美しい山や川、温泉があり、観光客が多いです。\n",
      "8. 荒尾市: 熊本県の北にある市で、世界遺産に登録されている「荒尾炭鉱」があります。炭鉱跡や、炭鉱関連の歴史的建造物が見られます。\n",
      "\n",
      "これらは、熊本県の観光地のいくつかです。熊本県は、自然豊かで、歴史的建造物や、温泉など、多様な観光地があります。\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"あなたは日本語で回答するアシスタントです。\"\n",
    "text = \"熊本県の観光地を教えて下さい。\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "token_ids = tokenizer.encode(\n",
    "    prompt, add_special_tokens=False,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    output_ids.tolist()[0][token_ids.size(1):], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825317af-85c2-4455-9e63-4bc3eb4cef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「莫山発言」とは、中国の哲学者・文芸評論家である莫山（Mao Dun）が行った発言のことを指します。\n",
      "\n",
      "莫山は、中国の近代文学を代表する作家でもあり、1920年代に「新文学」と呼ばれる文学運動を主導しました。彼は、新しい文学の方向性について、多くの発言を残しています。\n",
      "\n",
      "「莫山発言」は、通常、新しい文学の方向性や、文学の社会的役割についての彼の考え方を指します。例えば、「文学は社会を反映するものである」という発言は、モダン文学の基礎的な考え方となりました。\n",
      "\n",
      "しかし、具体的な「莫山発言」については、多くの場合、文脈に応じて異なる意味を持つことがあります。例えば、「文学は社会を反映するものである」という発言は、新しい文学の方向性を示すものであると同時に、文学の社会的役割についての彼の考え方を示すものでもあります。\n",
      "\n",
      "そのため、「莫山発言」という語は、文学の発展に大きく貢献した中国の哲学者・文芸評論家である莫山の発言を指す場合が多いです。\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"あなたは日本語で回答するアシスタントです。\"\n",
    "text = \"莫山先生の莫山発言。\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "token_ids = tokenizer.encode(\n",
    "    prompt, add_special_tokens=False,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    output_ids.tolist()[0][token_ids.size(1):], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
